{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes for course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is neural network?\n",
    "- simplest neural network - linear regression\n",
    "    - rectified linear unit (relu)\n",
    "- takes one or more features, applies function, returns output\n",
    "- Neural Networks (standard)\n",
    "- Convolutional Neural Networks\n",
    "- Recurrent Neural Networks\n",
    "- Hybrid or Custom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning with Neural Networks:\n",
    "- input (x) -> output (y)\n",
    "- applications:\n",
    "    - real estate - NN\n",
    "    - online advertising - NN\n",
    "    - photo tagging - CNN\n",
    "    - speech recognition - RNN\n",
    "    - machine translation - RNN\n",
    "    - automotive industry, autonomous driving - Hybrid/Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Data vs Unstructured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is Deep Learning taking off?\n",
    "- scale - more data means better model's performance\n",
    "- the more data you have the bigger should network be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(m) - size of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently we have seen 3 advances:\n",
    "- more data \n",
    "- better computational power\n",
    "- better algorithms - sigmoid function is slower than ReLU due to gradient being close to zero and moving forward slowly for sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Cycle:\n",
    "- Idea\n",
    "- Code\n",
    "- Experiment  \n",
    "\n",
    "Faster computation has sped up receiving feedback of experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classification:\n",
    "- creating feature vector for image\n",
    "- (n) - dimension of input feature vector\n",
    "- (x, y) - x is R^n feature vector, y is 0 or 1\n",
    "- matrix M\n",
    "- vector X - m x n\n",
    "- in python X.shape = (n, m)\n",
    "- vector Y - 1 x m\n",
    "- in python Y.shape = (1, m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression:\n",
    "- given input vector x produce y_hat that returns probability that given input vector is classified as 1 \n",
    "- w is weight vector, b is random numbers\n",
    "- y_hat should be between 0 and 1\n",
    "- y_hat is equal to sigmoid function applied to w^tx + b   /(z)\n",
    "- sigmoid = 1/1+e^(-z)\n",
    "- if z is large, sigmoid is going to 1, if it is small or negative sigmoid goes to 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression - cost function:\n",
    "- Loss (error) function:\n",
    "    - L(y^, y) = -(ylogy^ + (1-y)log(1-y^))\n",
    "- Cost function:\n",
    "    - J(w,b) = 1/m sum from i to m for L(y^(i), y(i))\n",
    "- Loss function is applied to single observation\n",
    "- Cost function is applied to vector of parameters and b parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent:\n",
    "- find w, b minimizing J(w,b)  \n",
    "- repeat derivative: dJ(w)/dw\n",
    "\n",
    "Cost function is used to have a convex function that will enable gradient descent to minimize it  \n",
    "\n",
    "alfa parameter - learning rate - constant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation Graph:\n",
    "- chain rule - product of derivatives\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent on m Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized version:0.06103515625ms\n",
      "For loop:0.4425048828125ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000)\n",
    "b = np.random.rand(1000)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "c= np.dot(a, b)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Vectorized version:\" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    c+= a[i] * b[i]\n",
    "toc = time.time()\n",
    "\n",
    "print (\"For loop:\" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset size\n",
    "m = 10\n",
    "# learning rate\n",
    "alfa = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(5, 1)\n",
    "b = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(w.T, X) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1 + np.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.randn(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = A - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27474965, -0.04021575,  0.26028093,  0.36767797,  0.6377069 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = 1/m * X * dz\n",
    "db = 1/m * np.sum(dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w - alfa*dw\n",
    "b = b - alfa*db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is turning lower dimensional vector, number into higher dimensional matrix to match higher dimensional part of equation in order to perform element-wise operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56. ,   0. ,   4.4,  68. ],\n",
       "       [  1.2, 104. ,  52. ,   8. ],\n",
       "       [  1.8, 135. ,  99. ,   0.9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[56, 1.2, 1.8], [0.0, 104, 135], \n",
    "              [4.4, 52, 99], [68, 8, 0.9]]).T\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59.  239.  155.4  76.9]\n"
     ]
    }
   ],
   "source": [
    "cal = A.sum(axis=0)\n",
    "print(cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94.9  0.   2.8 88.4]\n",
      " [ 2.  43.5 33.5 10.4]\n",
      " [ 3.1 56.5 63.7  1.2]]\n"
     ]
    }
   ],
   "source": [
    "percentage = np.round(100*A/cal.reshape(1,4),1)\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on python/numpy vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 1 array\n",
    "a = np.random.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(1, 5)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(3,3)\n",
    "b = np.random.randn(3,1)\n",
    "c = a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4754325 ,  0.09229966,  0.51109435],\n",
       "       [-0.84397007,  1.55916485,  1.22652647],\n",
       "       [-2.01315742, -1.01683205,  0.1550477 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.80622926],\n",
       "       [-0.20906048],\n",
       "       [-0.38928091]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38330759, -0.07441469, -0.41205922],\n",
       "       [ 0.17644079, -0.32595976, -0.25641822],\n",
       "       [ 0.78368376,  0.39583331, -0.06035711]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# number of input features in dataset X\n",
    "n = 3\n",
    "# number of training examples\n",
    "m = 10\n",
    "X = np.random.randn(n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1943709 ,  0.64804163,  1.46287113, -0.52703811, -0.61090275,\n",
       "        -0.50749665, -1.52642989, -0.43280595,  0.89773854, -0.77337107],\n",
       "       [-1.79411923, -2.38650283,  0.55769246,  0.42319424, -0.17346188,\n",
       "        -1.67947422,  1.68112723, -0.3718169 ,  0.34792506, -0.04487569],\n",
       "       [-1.00292944, -1.62679039,  0.07601192, -0.15329917, -1.93057677,\n",
       "         0.7077116 ,  0.93751814, -2.1130156 , -0.62818298, -0.50605365]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions:\n",
    "- sigmoid used only for binary classification\n",
    "- tanh is superior to sigmoid\n",
    "- relu is default choice for hidden layers  \n",
    "\n",
    "Using linear activation is almost useless and very rare - it produces linear output yhat from input set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives of activation functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_sigmoid = sigmoid * ( 1- sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_tanh = 1 - (tanh**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu = 0 if z < 0 else 1 if z > 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent for Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Initialize parameters randomly\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# powtorzyc, zaimplementowac jutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
